import os
import logging
import asyncio
import json
import tempfile
from datetime import datetime, timedelta
from typing import Dict, Any, Optional

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ ØªÙ„Ú¯Ø±Ø§Ù…
from telegram import Update
from telegram.ext import Application, MessageHandler, filters, ContextTypes

# Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ú¯ÙˆÚ¯Ù„
import google.generativeai as genai
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import Flow
from googleapiclient.discovery import build

# Ø³Ø§ÛŒØ± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡â€ŒÙ‡Ø§
import speech_recognition as sr
from pydub import AudioSegment
import notion_client
from PIL import Image
import numpy as np

logger = logging.getLogger(__name__)

class VoiceAssistantBot:
    def __init__(self, secrets: Dict[str, str]):
        self.secrets = secrets
        self.notion = notion_client.Client(auth=secrets['notion_key'])
        self.calendar_service = None
        self.recognizer = sr.Recognizer()
        self.notion_db_properties = {}

        try:
            genai.configure(api_key=secrets['gemini_api_key'])
            self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
            self.embedding_model = 'models/embedding-001'
            logging.info("âœ… Ú©Ù„Ø§ÛŒÙ†Øª Google Gemini Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯.")
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ú©Ù„Ø§ÛŒÙ†Øª Gemini: {e}")
            self.gemini_model = None

    def _discover_notion_db_properties(self, db_id: str):
        if not db_id: return
        try:
            db_info = self.notion.databases.retrieve(database_id=db_id)
            self.notion_db_properties[db_id] = db_info['properties']
            logging.info(f"âœ… Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ {db_id} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯.")
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø³Ø§Ø®ØªØ§Ø± Ø¯ÛŒØªØ§Ø¨ÛŒØ³ {db_id}: {e}")

    def _get_google_auth_creds(self) -> Optional[Credentials]:
        try:
            google_creds_json = json.loads(self.secrets['google_creds'])
            with tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.json') as f:
                json.dump(google_creds_json, f)
                creds_path = f.name
            
            flow = Flow.from_client_secrets_file(
                creds_path,
                scopes=['https://www.googleapis.com/auth/calendar'],
                redirect_uri='urn:ietf:wg:oauth:2.0:oob'
            )

            auth_url, _ = flow.authorization_url(prompt='consent')
            print("\n" + "="*70 + "\nğŸ”— Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ú¯ÙˆÚ¯Ù„ Ú©Ù„Ù†Ø¯Ø±\n" + f"1. Ù„Ø·ÙØ§Ù‹ Ø±ÙˆÛŒ Ù„ÛŒÙ†Ú© Ø²ÛŒØ± Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯:\n{auth_url}")
            print("\n2. Ø¨Ù‡ Ø­Ø³Ø§Ø¨ Ú¯ÙˆÚ¯Ù„ Ø®ÙˆØ¯ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ø¯Ù‡ÛŒØ¯ Ùˆ Ú©Ø¯ Ø±Ø§ Ú©Ù¾ÛŒ Ú©Ù†ÛŒØ¯.")
            auth_code = input("3. Ú©Ø¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ ÙˆØ§Ø±Ø¯ Ú©Ø±Ø¯Ù‡ Ùˆ Enter Ø±Ø§ Ø¨Ø²Ù†ÛŒØ¯: ").strip()
            
            flow.fetch_token(code=auth_code)
            os.unlink(creds_path)
            return flow.credentials
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª Ú¯ÙˆÚ¯Ù„: {e}", exc_info=True)
            return None

    def setup_google_calendar(self) -> bool:
        print("\nâ³ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³ ØªÙ‚ÙˆÛŒÙ… Ú¯ÙˆÚ¯Ù„...")
        creds = self._get_google_auth_creds()
        if creds:
            self.calendar_service = build('calendar', 'v3', credentials=creds)
            print("âœ… Ø³Ø±ÙˆÛŒØ³ ØªÙ‚ÙˆÛŒÙ… Ú¯ÙˆÚ¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯.")
            return True
        print("âŒ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³Ø±ÙˆÛŒØ³ ØªÙ‚ÙˆÛŒÙ… Ú¯ÙˆÚ¯Ù„ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")
        return False

    async def _analyze_text_with_gemini(self, text: str) -> Optional[Dict[str, Any]]:
        if not self.gemini_model:
            logging.error("Ú©Ù„Ø§ÛŒÙ†Øª Gemini Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª.")
            return None
        
        logging.info("ğŸ¤– Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙ† Ø¨Ø§ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Gemini...")
        prompt = f"""
        Analyze the following Persian text and determine the user's intent.
        The possible intents are: CALENDAR_EVENT, KNOWLEDGE_STORAGE, or QUERY.

        - **CALENDAR_EVENT**: User wants to schedule something. Extract "summary" and "start_time" in ISO 8601 format.
          Example: "ÙØ±Ø¯Ø§ Ø³Ø§Ø¹Øª Û±Û° ØµØ¨Ø­ ÛŒÚ© Ø¬Ù„Ø³Ù‡ Ø¨Ø§ ØªÛŒÙ… ÙØ±ÙˆØ´ Ø¨Ø°Ø§Ø±" -> {{"intent": "CALENDAR_EVENT", "entities": {{"summary": "Ø¬Ù„Ø³Ù‡ Ø¨Ø§ ØªÛŒÙ… ÙØ±ÙˆØ´", "start_time": "YYYY-MM-DDTHH:MM:SSZ"}}}}

        - **KNOWLEDGE_STORAGE**: User wants to save information. Extract the "content".
          Example: "Ø§ÛŒÙ† Ø§ÛŒØ¯Ù‡ Ø±Ùˆ Ø«Ø¨Øª Ú©Ù†: Ø¨Ø§ÛŒØ¯ Ø§Ø² RAG Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¨Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…." -> {{"intent": "KNOWLEDGE_STORAGE", "entities": {{"content": "Ø¨Ø§ÛŒØ¯ Ø§Ø² RAG Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø±Ø¨Ø§Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒÙ…."}}}}

        - **QUERY**: User is asking a question. Extract the "query".
          Example: "Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù† Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†ÛŒ Ø¨ÙˆØ¯ØŸ" -> {{"intent": "QUERY", "entities": {{"query": "Ø§ÛŒØ¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ù† Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ú†ÛŒ Ø¨ÙˆØ¯ØŸ"}}}}

        - If the intent is unclear, return null.

        Current time for reference: {datetime.now().isoformat()}
        User's text: "{text}"

        Respond with a single JSON object.
        """
        try:
            response = self.gemini_model.generate_content(prompt)
            json_text = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(json_text)
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Gemini: {e}", exc_info=True)
            return None

    async def _create_calendar_event(self, entities: Dict[str, Any]) -> str:
        if not self.calendar_service:
            return "Ø³Ø±ÙˆÛŒØ³ ØªÙ‚ÙˆÛŒÙ… Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª."
        try:
            summary = entities.get("summary", "Ø±ÙˆÛŒØ¯Ø§Ø¯ Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†")
            start_time_str = entities.get("start_time")
            if not start_time_str:
                return "Ø²Ù…Ø§Ù† Ø±ÙˆÛŒØ¯Ø§Ø¯ Ù…Ø´Ø®Øµ Ù†Ø´Ø¯."
                
            start_time = datetime.fromisoformat(start_time_str.replace('Z', '+00:00'))
            end_time = start_time + timedelta(hours=1)

            event = {
                'summary': summary,
                'start': {'dateTime': start_time.isoformat(), 'timeZone': 'UTC'},
                'end': {'dateTime': end_time.isoformat(), 'timeZone': 'UTC'},
            }
            created_event = self.calendar_service.events().insert(calendarId='primary', body=event).execute()
            return f"âœ… Ø±ÙˆÛŒØ¯Ø§Ø¯ Â«{summary}Â» Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± ØªÙ‚ÙˆÛŒÙ… Ú¯ÙˆÚ¯Ù„ Ø«Ø¨Øª Ø´Ø¯."
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø±ÙˆÛŒØ¯Ø§Ø¯ ØªÙ‚ÙˆÛŒÙ…: {e}", exc_info=True)
            return "Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ø±ÙˆÛŒØ¯Ø§Ø¯ ØªÙ‚ÙˆÛŒÙ… Ù¾ÛŒØ´ Ø¢Ù…Ø¯."

    async def _add_to_knowledge_base(self, content: str) -> str:
        db_id = self.secrets.get('notion_kb_db_id')
        if not db_id: return "Ø®Ø·Ø§: Ø´Ù†Ø§Ø³Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."

        try:
            logging.info(f"ğŸ§  Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Embedding Ø¨Ø§ Ù…Ø¯Ù„ {self.embedding_model}...")
            embedding_response = genai.embed_content(
                model=self.embedding_model,
                content=content,
                task_type="RETRIEVAL_DOCUMENT"
            )
            embedding_vector = embedding_response['embedding']
            embedding_str = json.dumps(embedding_vector)
            chunk_size = 2000
            embedding_chunks = [{"text": {"content": chunk}} for chunk in [embedding_str[i:i + chunk_size] for i in range(0, len(embedding_str), chunk_size)]]

            properties = {
                "Name": {"title": [{"text": {"content": content[:150]}}]},
                "Content": {"rich_text": [{"text": {"content": content}}]},
                "Embedding": {"rich_text": embedding_chunks}
            }
            self.notion.pages.create(parent={"database_id": db_id}, properties=properties)
            return "âœ… Ù…Ø·Ù„Ø¨ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´ Ù†ÙˆØ´Ù† Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯."
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´: {e}", exc_info=True)
            return "Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¯Ø± Ù†ÙˆØ´Ù† Ù¾ÛŒØ´ Ø¢Ù…Ø¯."

    async def _query_knowledge_base(self, query: str) -> str:
        db_id = self.secrets.get('notion_kb_db_id')
        if not db_id: return "Ø®Ø·Ø§: Ø´Ù†Ø§Ø³Ù‡ Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´ ØªØ¹Ø±ÛŒÙ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª."
        
        try:
            logging.info(f"ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø³Ø§Ø®Øª Embedding Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ Ø¨Ø§ {self.embedding_model}...")
            query_embedding_response = genai.embed_content(model=self.embedding_model, content=query, task_type="RETRIEVAL_QUERY")
            query_vector = np.array(query_embedding_response['embedding'])

            all_pages = []
            cursor = None
            while True:
                response = self.notion.databases.query(database_id=db_id, start_cursor=cursor)
                all_pages.extend(response.get('results', []))
                if not response.get('has_more'): break
                cursor = response.get('next_cursor')
            
            if not all_pages: return "Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ø´Ù…Ø§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª."
            logging.info(f"âœ… {len(all_pages)} ØµÙØ­Ù‡ Ø§Ø² Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´ Ø¨Ø§Ø²ÛŒØ§Ø¨ÛŒ Ø´Ø¯.")

            page_similarities = []
            for page in all_pages:
                props = page.get('properties', {})
                embedding_chunks = props.get("Embedding", {}).get('rich_text', [])
                if not embedding_chunks: continue
                embedding_json = "".join([chunk.get('text', {}).get('content', '') for chunk in embedding_chunks])
                try:
                    doc_vector = np.array(json.loads(embedding_json))
                    similarity = np.dot(query_vector, doc_vector) / (np.linalg.norm(query_vector) * np.linalg.norm(doc_vector))
                    page_content = props.get("Content", {}).get('rich_text', [{}])[0].get('text', {}).get('content', 'Ù…Ø­ØªÙˆØ§ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª')
                    page_similarities.append((similarity, page_content))
                except (json.JSONDecodeError, ValueError) as e:
                    logging.warning(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Embedding Ø¨Ø±Ø§ÛŒ ØµÙØ­Ù‡ {page.get('id')}: {e}")
                    continue
            
            page_similarities.sort(key=lambda x: x[0], reverse=True)
            relevant_docs = [doc[1] for doc in page_similarities if doc[0] > 0.7][:3]
            
            if not relevant_docs: return "Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù…Ø·Ù„Ø¨ Ù…Ø±ØªØ¨Ø·ÛŒ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ø´Ù…Ø§ Ù¾ÛŒØ¯Ø§ Ù†Ú©Ø±Ø¯Ù…."
            logging.info(f"âœ… {len(relevant_docs)} Ù†Ú©ØªÙ‡ Ù…Ø±ØªØ¨Ø· Ø¨Ø±Ø§ÛŒ Ù¾Ø§Ø³Ø®â€ŒÚ¯ÙˆÛŒÛŒ ÛŒØ§ÙØª Ø´Ø¯.")

            context_str = "\n\n---\n\n".join(relevant_docs)
            final_prompt = f"Ø´Ù…Ø§ ÛŒÚ© Ø¯Ø³ØªÛŒØ§Ø± Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ Ù‡Ø³ØªÛŒØ¯ Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ø´Ø®ØµÛŒ Ú©Ø§Ø±Ø¨Ø± Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ù¾Ø§Ø³Ø® Ù…ÛŒâ€ŒØ¯Ù‡ÛŒØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Â«Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø·Â» Ø²ÛŒØ±ØŒ Ø¨Ù‡ Â«Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±Â» ÛŒÚ© Ù¾Ø§Ø³Ø® Ø¬Ø§Ù…Ø¹ Ùˆ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ø¨Ø¯Ù‡ÛŒØ¯.\n\n**Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù…Ø±ØªØ¨Ø· Ø§Ø² Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´:**\n{context_str}\n\n**Ø³ÙˆØ§Ù„ Ú©Ø§Ø±Ø¨Ø±:**\n{query}\n\n**Ù¾Ø§Ø³Ø® Ø´Ù…Ø§ (Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ):**"
            
            logging.info("âœï¸ Ø¯Ø± Ø­Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ù¾Ø§Ø³Ø® Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø§ Gemini...")
            final_response = self.gemini_model.generate_content(final_prompt)
            return final_response.text
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ÙØ±Ø¢ÛŒÙ†Ø¯ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ: {e}", exc_info=True)
            return f"ÛŒÚ© Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ù‡Ù†Ú¯Ø§Ù… Ø¬Ø³ØªØ¬Ùˆ Ø±Ø® Ø¯Ø§Ø¯: {e}"

    async def _process_user_request(self, text: str, update: Update):
        await update.message.reply_chat_action('typing')
        analysis = await self._analyze_text_with_gemini(text)
        
        if not analysis:
            await update.message.reply_text("âŒ Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆÛŒØ³ Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ (Gemini) Ù¾ÛŒØ´ Ø¢Ù…Ø¯.")
            return

        intent = analysis.get("intent")
        entities = analysis.get("entities", {})

        if intent == "CALENDAR_EVENT":
            response_text = await self._create_calendar_event(entities)
            await update.message.reply_text(response_text)
        elif intent == "KNOWLEDGE_STORAGE":
            content = entities.get("content", text)
            response_text = await self._add_to_knowledge_base(content)
            await update.message.reply_text(response_text)
        elif intent == "QUERY":
            query = entities.get("query", text)
            await update.message.reply_text("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ù†Ø´ Ø´Ù…Ø§...")
            answer = await self._query_knowledge_base(query)
            await update.message.reply_text(answer)
        else:
            await update.message.reply_text("ğŸ¤” Ù…ØªÙˆØ¬Ù‡ Ù…Ù†Ø¸ÙˆØ± Ø´Ù…Ø§ Ù†Ø´Ø¯Ù…. Ù„Ø·ÙØ§Ù‹ ÙˆØ§Ø¶Ø­â€ŒØªØ± Ø¨ÛŒØ§Ù† Ú©Ù†ÛŒØ¯.")

    async def _convert_voice_to_text(self, voice_file_path: str) -> str:
        logging.info("ğŸµ Ø¯Ø± Ø­Ø§Ù„ ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†...")
        try:
            audio = AudioSegment.from_ogg(voice_file_path)
            wav_path = voice_file_path + ".wav"
            audio.export(wav_path, format="wav")
            with sr.AudioFile(wav_path) as source:
                audio_data = self.recognizer.record(source)
            text = self.recognizer.recognize_google(audio_data, language='fa-IR')
            os.remove(wav_path)
            return text
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªØ¨Ø¯ÛŒÙ„ ØµØ¯Ø§ Ø¨Ù‡ Ù…ØªÙ†: {e}", exc_info=True)
            if 'wav_path' in locals() and os.path.exists(wav_path):
                os.remove(wav_path)
            return ""

    async def handle_voice_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text("ğŸ¤ Ù¾ÛŒØ§Ù… ØµÙˆØªÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ ØµØ¨Ø± Ú©Ù†ÛŒØ¯...")
        voice = update.message.voice
        with tempfile.NamedTemporaryFile(suffix=".ogg", delete=False) as temp_file:
            voice_file = await context.bot.get_file(voice.file_id)
            await voice_file.download_to_drive(temp_file.name)
            voice_path = temp_file.name
        
        text = await self._convert_voice_to_text(voice_path)
        os.unlink(voice_path)

        if text:
            await update.message.reply_text(f"ğŸ“ Ù…ØªÙ† Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ø´Ø¯Ù‡: Â«{text}Â»")
            await self._process_user_request(text, update)
        else:
            await update.message.reply_text("âŒ Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ù†ØªÙˆØ§Ù†Ø³ØªÙ… ØµØ¯Ø§ÛŒØªØ§Ù† Ø±Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ù‡Ù….")

    async def handle_text_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        user_text = update.message.text
        logging.info(f"âŒ¨ï¸ Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: '{user_text}'")
        await self._process_user_request(user_text, update)

    async def handle_photo_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        await update.message.reply_text("ğŸ–¼ï¸ ØªØµÙˆÛŒØ± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯. Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ØªÙ† Ø¨Ø§ Gemini...")
        photo_file = await context.bot.get_file(update.message.photo[-1].file_id)
        with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as temp_photo:
            await photo_file.download_to_drive(temp_photo.name)
            photo_path = temp_photo.name
        
        try:
            img = Image.open(photo_path)
            response = self.gemini_model.generate_content(["Extract all text from this image in Persian.", img])
            extracted_text = response.text
            os.unlink(photo_path)
            
            if extracted_text and extracted_text.strip():
                await update.message.reply_text(f"ğŸ“ Ù…ØªÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡:\n\nÂ«{extracted_text}Â»\n\nğŸ“š Ø¯Ø± Ø­Ø§Ù„ Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ù‡ Ú©ØªØ§Ø¨Ø®Ø§Ù†Ù‡ Ø¯Ø§Ù†Ø´...")
                response_text = await self._add_to_knowledge_base(extracted_text)
                await update.message.reply_text(response_text)
            else:
                await update.message.reply_text("Ù…ØªÙ†ÛŒ Ø¯Ø± ØªØµÙˆÛŒØ± ÛŒØ§ÙØª Ù†Ø´Ø¯.")
        except Exception as e:
            logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±: {e}", exc_info=True)
            await update.message.reply_text("Ù…Ø´Ú©Ù„ÛŒ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ù¾ÛŒØ´ Ø¢Ù…Ø¯.")
            if os.path.exists(photo_path):
                os.unlink(photo_path)

    async def run(self):
        logging.info("\nğŸš€ Ø¯Ø± Ø­Ø§Ù„ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø±Ø¨Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…...")
        app = Application.builder().token(self.secrets['telegram']).build()
        
        app.add_handler(MessageHandler(filters.VOICE, self.handle_voice_message))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text_message))
        app.add_handler(MessageHandler(filters.PHOTO, self.handle_photo_message))
        
        logging.info("ğŸ”¥ Ø±Ø¨Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ÙØ¹Ø§Ù„ Ø´Ø¯! Ø¢Ù…Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù….")
        await app.run_polling()
